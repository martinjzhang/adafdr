### record for fold_2
# K=5, alpha=0.10, n_full=16734, n_itr=1500, random_state=0
# n_sample=16734
# p<0.000001: 700
# p<0.000010: 848
# p<0.000100: 1034
# p<0.000500: 1236

## method_init starts
# t_BH=0.012218, n_null=5871, n_alt=2049
## Learning null distribution
## Learning alternative distribution

## rescale_mirror: before optimization
# quantile of t (1,25,75,99): [0.0002 0.0007 0.3564 0.8479]
# gamma_pre=0.1988
# gamma_l=0.1633, gamma_u=0.1837, D_hat=2905, FD_hat=285, alpha_hat=0.0981
# gamma_l=0.1735, gamma_u=0.1837, D_hat=2920, FD_hat=289, alpha_hat=0.0990
# final output: gamma=0.0360

## choosing lambda0
## lambda0=27.6, D=2932, FD_hat=293, alpha_hat=0.100
# lambda0=41.4, D_apr=2826.6 (r err=0.036), FD_hat_apr=524.066 (r err=0.789)
# lambda0=55.2, D_apr=2863.6 (r err=0.023), FD_hat_apr=447.597 (r err=0.528)
# lambda0=69.0, D_apr=2884.4 (r err=0.016), FD_hat_apr=404.639 (r err=0.381)
# lambda0=82.8, D_apr=2896.8 (r err=0.012), FD_hat_apr=378.104 (r err=0.290)
# lambda0=96.6, D_apr=2904.6 (r err=0.009), FD_hat_apr=360.812 (r err=0.231)
# lambda0=110.4, D_apr=2909.9 (r err=0.008), FD_hat_apr=349.045 (r err=0.191)
# lambda0=124.2, D_apr=2913.6 (r err=0.006), FD_hat_apr=340.699 (r err=0.163)
# lambda0=138.0, D_apr=2916.4 (r err=0.005), FD_hat_apr=334.537 (r err=0.142)
# lambda0=151.8, D_apr=2918.5 (r err=0.005), FD_hat_apr=329.812 (r err=0.126)
# lambda0=165.6, D_apr=2920.1 (r err=0.004), FD_hat_apr=326.067 (r err=0.113)
# lambda0=179.4, D_apr=2921.5 (r err=0.004), FD_hat_apr=323.016 (r err=0.102)
# lambda0=193.2, D_apr=2922.6 (r err=0.003), FD_hat_apr=320.471 (r err=0.094)
# lambda0=207.0, D_apr=2923.5 (r err=0.003), FD_hat_apr=318.311 (r err=0.086)
# lambda0=220.8, D_apr=2924.3 (r err=0.003), FD_hat_apr=316.449 (r err=0.080)
# lambda0=234.6, D_apr=2924.9 (r err=0.002), FD_hat_apr=314.827 (r err=0.074)
# lambda0=248.5, D_apr=2925.5 (r err=0.002), FD_hat_apr=313.401 (r err=0.070)
# lambda0=262.3, D_apr=2926.0 (r err=0.002), FD_hat_apr=312.136 (r err=0.065)
# lambda0=276.1, D_apr=2926.5 (r err=0.002), FD_hat_apr=311.009 (r err=0.061)
# lambda0=289.9, D_apr=2926.9 (r err=0.002), FD_hat_apr=309.998 (r err=0.058)
# lambda0=303.7, D_apr=2927.3 (r err=0.002), FD_hat_apr=309.088 (r err=0.055)
# lambda0=317.5, D_apr=2927.6 (r err=0.002), FD_hat_apr=308.264 (r err=0.052)
# lambda0=331.3, D_apr=2927.9 (r err=0.001), FD_hat_apr=307.516 (r err=0.050)
# lambda0=345.1, D_apr=2928.1 (r err=0.001), FD_hat_apr=306.834 (r err=0.047)
# lambda0=358.9, D_apr=2928.4 (r err=0.001), FD_hat_apr=306.211 (r err=0.045)
# lambda0=372.7, D_apr=2928.6 (r err=0.001), FD_hat_apr=305.640 (r err=0.043)
# lambda0=386.5, D_apr=2928.8 (r err=0.001), FD_hat_apr=305.114 (r err=0.041)
# lambda0=400.3, D_apr=2929.0 (r err=0.001), FD_hat_apr=304.630 (r err=0.040)
# lambda0=414.1, D_apr=2929.2 (r err=0.001), FD_hat_apr=304.182 (r err=0.038)
# lambda0=427.9, D_apr=2929.3 (r err=0.001), FD_hat_apr=303.767 (r err=0.037)
# lambda0=441.7, D_apr=2929.5 (r err=0.001), FD_hat_apr=303.382 (r err=0.035)
# lambda0=455.5, D_apr=2929.6 (r err=0.001), FD_hat_apr=303.023 (r err=0.034)
# lambda0=469.3, D_apr=2929.7 (r err=0.001), FD_hat_apr=302.688 (r err=0.033)
# lambda0=483.1, D_apr=2929.8 (r err=0.001), FD_hat_apr=302.375 (r err=0.032)
# lambda0=496.9, D_apr=2929.9 (r err=0.001), FD_hat_apr=302.081 (r err=0.031)
# lambda0=510.7, D_apr=2930.0 (r err=0.001), FD_hat_apr=301.806 (r err=0.030)
# lambda0=524.5, D_apr=2930.1 (r err=0.001), FD_hat_apr=301.547 (r err=0.029)
# lambda0=538.3, D_apr=2930.2 (r err=0.001), FD_hat_apr=301.303 (r err=0.028)
# lambda0=552.1, D_apr=2930.3 (r err=0.001), FD_hat_apr=301.074 (r err=0.028)
# lambda0=565.9, D_apr=2930.4 (r err=0.001), FD_hat_apr=300.856 (r err=0.027)
# lambda0=579.7, D_apr=2930.5 (r err=0.001), FD_hat_apr=300.651 (r err=0.026)
# lambda0=593.5, D_apr=2930.5 (r err=0.001), FD_hat_apr=300.456 (r err=0.025)
# lambda0=607.3, D_apr=2930.6 (r err=0.000), FD_hat_apr=300.272 (r err=0.025)
# lambda0=621.1, D_apr=2930.6 (r err=0.000), FD_hat_apr=300.096 (r err=0.024)
# lambda0=634.9, D_apr=2930.7 (r err=0.000), FD_hat_apr=299.930 (r err=0.024)
# lambda0=648.7, D_apr=2930.7 (r err=0.000), FD_hat_apr=299.771 (r err=0.023)
# lambda0=662.5, D_apr=2930.8 (r err=0.000), FD_hat_apr=299.619 (r err=0.023)
# lambda0=676.3, D_apr=2930.8 (r err=0.000), FD_hat_apr=299.475 (r err=0.022)
# lambda0=690.1, D_apr=2930.9 (r err=0.000), FD_hat_apr=299.337 (r err=0.022)
# lambda0=703.9, D_apr=2930.9 (r err=0.000), FD_hat_apr=299.206 (r err=0.021)
# lambda0=717.7, D_apr=2931.0 (r err=0.000), FD_hat_apr=299.080 (r err=0.021)
# lambda0=731.5, D_apr=2931.0 (r err=0.000), FD_hat_apr=298.959 (r err=0.020)
# lambda0=745.4, D_apr=2931.0 (r err=0.000), FD_hat_apr=298.843 (r err=0.020)

## rescale_mirror: after method_single_fold
# quantile of t (1,25,75,99): [0.     0.0001 0.0778 0.1205]
# gamma_pre=1.0000
# gamma_l=1.0066, gamma_u=1.1185, D_hat=3099, FD_hat=323, alpha_hat=0.1042
# gamma_l=1.0066, gamma_u=1.0626, D_hat=3076, FD_hat=313, alpha_hat=0.1018
# gamma_l=1.0066, gamma_u=1.0346, D_hat=3067, FD_hat=307, alpha_hat=0.1001
# gamma_l=1.0066, gamma_u=1.0206, D_hat=3063, FD_hat=303, alpha_hat=0.0989
# final output: gamma=1.0171

## rescale_mirror: cv
# quantile of t (1,25,75,99): [0.     0.0001 0.0778 0.1205]
# gamma_pre=1.0000
# gamma_l=1.0084, gamma_u=1.1205, D_hat=3085, FD_hat=317, alpha_hat=0.1028
# gamma_l=1.0084, gamma_u=1.0645, D_hat=3059, FD_hat=310, alpha_hat=0.1013
# gamma_l=1.0084, gamma_u=1.0364, D_hat=3045, FD_hat=306, alpha_hat=0.1005
# gamma_l=1.0084, gamma_u=1.0224, D_hat=3041, FD_hat=302, alpha_hat=0.0993
# final output: gamma=1.0189

## Test result with method_cv fold_2
# Num of discovery: 3043

